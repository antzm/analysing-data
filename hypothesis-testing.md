# Hypothesis Testing

## The theory behind the z-test

We have a population, with the parameters μ and σ, that follows the normal distribution. In practical terms (i.e. in the vast majority of cases), the population mean (μ) and the population standard deviation (σ) are actually unknown and we use the sample mean (x bar) and the sample standard deviation (s) to calculate, or rather, estimate them.
(In statistics, Greek letters refer always to the population, while English letters refer always to the sample. In simplified terms, we know the English letters and based on that information, we try to estimate the Greek letters i.e. We know the sample and we try, from that sample, to make statistical inference for the population).
 
Example:
We have a smartphone with a battery that lasts, on average, for 23 hours and with a standard deviation of 1 hour (based on a sample of 100 phones).
Then, an updated model with a new battery comes to the market and based on a sample of 100 phones, we find that the new battery lasts, on average, for 25 hours, with a standard deviation of 2 hours.
Is the new battery better than the previous battery?

## Comparing two distributions

When comparing numbers, it’s easy to conclude if two numbers are equal or not, and then, to find out which one is the greatest and which one is the smallest.  

In statistics though, things are completely different as we always compare a set of numbers with another set of numbers. We compare a set of numbers, that when put on a graph are distributed in a certain way, with another set of numbers, that when put on a graph are distributed in a different way. In other words, in statistics we always compare one distribution of numbers, with another distribution of numbers and we want to find out if those distributions are “equal”, or if they are different. And if the are different, which one is smallest, and which one is greatest.  

In statistics though, we cannot use the word equal to compare two distributions, as it’s practically impossible to compare two sets of numbers, that come from two different samples, and to find out that those sets are exactly the same.
For this reason, we use a very specialized and extremely important terminology in statistics:  

When something is “equal” in statistical terms, we say that there are no statistically significant differences between variable1 and variable2, although variable1 could be 10 and variable2 could be 100. Yes, they may look completely different but from the statistical point of view, there are no statistically significant differences between those two variables.  

On the other hand, we may have two variables with the value of 1,23 and 1,25 and to find out that those variables are statistically significant different i.e. not “equal” in statistical terms.

